{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6078b2229b52d7287696cfdb10f946c4593b8ef1"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "eb0b9e0fcfecd8bd2e0b2323d34bed825f54f01a"
   },
   "outputs": [],
   "source": [
    "# Import all packages required for this project. \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import sys\n",
    "import pandas\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4db67b9650ad6a5d01bd7dccb11d922b891b1b9b"
   },
   "outputs": [],
   "source": [
    "# Read the files and name them accordingly\n",
    "iplmatches = pd.read_csv('matches.csv')\n",
    "ipldelivery = pd.read_csv('deliveries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a985168ca61b451fc95192010f5cad113f25d0ed"
   },
   "outputs": [],
   "source": [
    "#Ensure that the file is being read correctly\n",
    "ipldelivery.head(5)\n",
    "iplmatches.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b14bc55d1fac5fb18a2f693478af513a16e73064"
   },
   "outputs": [],
   "source": [
    "## BATSMEN DATA GROUPED BY MATCH\n",
    "# Here the data is grouped to provide deeper depth of statistics and later for the team classificaiton\n",
    "\n",
    "batsman_grp = ipldelivery.groupby([\"match_id\", \"inning\", \"batting_team\", \"batsman\"])\n",
    "batsmen = batsman_grp[\"batsman_runs\"].sum().reset_index()\n",
    "\n",
    "# Ignore the wide balls.\n",
    "balls_faced = ipldelivery[ipldelivery[\"wide_runs\"] == 0]\n",
    "balls_faced = balls_faced.groupby([\"match_id\", \"inning\", \"batsman\"])[\"batsman_runs\"].count().reset_index()\n",
    "balls_faced.columns = [\"match_id\", \"inning\", \"batsman\", \"balls_faced\"]\n",
    "batsmen = batsmen.merge(balls_faced, left_on=[\"match_id\", \"inning\", \"batsman\"], \n",
    "                        right_on=[\"match_id\", \"inning\", \"batsman\"], how=\"left\")\n",
    "\n",
    "fours = ipldelivery[ ipldelivery[\"batsman_runs\"] == 4]\n",
    "sixes = ipldelivery[ ipldelivery[\"batsman_runs\"] == 6]\n",
    "\n",
    "fours_per_batsman = fours.groupby([\"match_id\", \"inning\", \"batsman\"])[\"batsman_runs\"].count().reset_index()\n",
    "sixes_per_batsman = sixes.groupby([\"match_id\", \"inning\", \"batsman\"])[\"batsman_runs\"].count().reset_index()\n",
    "\n",
    "fours_per_batsman.columns = [\"match_id\", \"inning\", \"batsman\", \"4s\"]\n",
    "sixes_per_batsman.columns = [\"match_id\", \"inning\", \"batsman\", \"6s\"]\n",
    "\n",
    "batsmen = batsmen.merge(fours_per_batsman, left_on=[\"match_id\", \"inning\", \"batsman\"], \n",
    "                        right_on=[\"match_id\", \"inning\", \"batsman\"], how=\"left\")\n",
    "batsmen = batsmen.merge(sixes_per_batsman, left_on=[\"match_id\", \"inning\", \"batsman\"], \n",
    "                        right_on=[\"match_id\", \"inning\", \"batsman\"], how=\"left\")\n",
    "batsmen['SR'] = np.round(batsmen['batsman_runs'] / batsmen['balls_faced'] * 100, 2)\n",
    "\n",
    "for col in [\"batsman_runs\", \"4s\", \"6s\", \"balls_faced\", \"SR\"]:\n",
    "    batsmen[col] = batsmen[col].fillna(0)\n",
    "\n",
    "dismissals = ipldelivery[ pd.notnull(ipldelivery[\"player_dismissed\"])]\n",
    "dismissals = dismissals[[\"match_id\", \"inning\", \"player_dismissed\", \"dismissal_kind\", \"fielder\"]]\n",
    "dismissals.rename(columns={\"player_dismissed\": \"batsman\"}, inplace=True)\n",
    "batsmen = batsmen.merge(dismissals, left_on=[\"match_id\", \"inning\", \"batsman\"], \n",
    "                        right_on=[\"match_id\", \"inning\", \"batsman\"], how=\"left\")\n",
    "\n",
    "batsmen = iplmatches[['id','season']].merge(batsmen, left_on = 'id', right_on = 'match_id', how = 'left').drop('id', axis = 1)\n",
    "batsmen.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2238b67daf20e8ae453503568105f19785d002fe"
   },
   "outputs": [],
   "source": [
    "## Bowlers grouped by sets of data\n",
    "# Data is grouped for bowlers to provide greater depth of information. Very important for the regression analysis.\n",
    "\n",
    "bowler_grp = ipldelivery.groupby([\"match_id\", \"inning\", \"bowling_team\", \"bowler\", \"over\"])\n",
    "bowlers = bowler_grp[\"total_runs\", \"wide_runs\", \"bye_runs\", \"legbye_runs\", \"noball_runs\"].sum().reset_index()\n",
    "\n",
    "bowlers[\"runs\"] = bowlers[\"total_runs\"] - (bowlers[\"bye_runs\"] + bowlers[\"legbye_runs\"])\n",
    "bowlers[\"extras\"] = bowlers[\"wide_runs\"] + bowlers[\"noball_runs\"]\n",
    "\n",
    "del( bowlers[\"bye_runs\"])\n",
    "del( bowlers[\"legbye_runs\"])\n",
    "del( bowlers[\"total_runs\"])\n",
    "\n",
    "dismissal_kinds_for_bowler = [\"bowled\", \"caught\", \"lbw\", \"stumped\", \"caught and bowled\", \"hit wicket\"]\n",
    "dismissals = ipldelivery[ipldelivery[\"dismissal_kind\"].isin(dismissal_kinds_for_bowler)]\n",
    "dismissals = dismissals.groupby([\"match_id\", \"inning\", \"bowling_team\", \"bowler\", \"over\"])[\"dismissal_kind\"].count().reset_index()\n",
    "dismissals.rename(columns={\"dismissal_kind\": \"wickets\"}, inplace=True)\n",
    "\n",
    "bowlers = bowlers.merge(dismissals, left_on=[\"match_id\", \"inning\", \"bowling_team\", \"bowler\", \"over\"], \n",
    "                        right_on=[\"match_id\", \"inning\", \"bowling_team\", \"bowler\", \"over\"], how=\"left\")\n",
    "bowlers[\"wickets\"] = bowlers[\"wickets\"].fillna(0)\n",
    "\n",
    "bowlers_over = bowlers.groupby(['match_id', 'inning', 'bowling_team', 'bowler'])['over'].count().reset_index()\n",
    "bowlers = bowlers.groupby(['match_id', 'inning', 'bowling_team', 'bowler']).sum().reset_index().drop('over', 1)\n",
    "bowlers = bowlers_over.merge(bowlers, on=[\"match_id\", \"inning\", \"bowling_team\", \"bowler\"], how = 'left')\n",
    "bowlers['Econ'] = np.round(bowlers['runs'] / bowlers['over'] , 2)\n",
    "bowlers = iplmatches[['id','season']].merge(bowlers, left_on = 'id', right_on = 'match_id', how = 'left').drop('id', axis = 1)\n",
    "\n",
    "bowlers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fb1030282681c758cac5dea7ebd4a57b80d3d95"
   },
   "outputs": [],
   "source": [
    "# Ensure the data is grouped carefully. Name them accordingly as above. \n",
    "iplmatches.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7e62dd713e24efab7056617654896350be4f1c6"
   },
   "source": [
    "Below is some Data Visualization techniques and basic Statistical Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1140668c7f508f700605e7ae2c1db0e9a5f4399"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x = 'season', data = iplmatches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1760b008017e0eaee00cb0e2911a11b0c6e6cc77"
   },
   "outputs": [],
   "source": [
    "sns.countplot( x = 'toss_winner', data = iplmatches)\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b31eec9ca59b872875b49e5272ae2d5de81dfbf9"
   },
   "outputs": [],
   "source": [
    "winneroft = iplmatches['toss_winner'] == iplmatches['winner']\n",
    "winneroft.groupby(winneroft).size()\n",
    "sns.countplot(winneroft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ebee6f2438a7a26ed40b1f3b0d522984d7e8676"
   },
   "outputs": [],
   "source": [
    "winneroftoss = iplmatches[(iplmatches['toss_winner']) == (iplmatches['winner'])]\n",
    "\n",
    "wot = sns.countplot( x = 'winner', hue='season', data=winneroftoss)\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel(\"Teams\")\n",
    "plt.ylabel(\"Number of Wins\")\n",
    "plt.title(\"Number of Teams who won, given they win the toss, every season\")\n",
    "plt.show(wot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3527f526850b7336548c6ac84cdd18dea441c7b7"
   },
   "outputs": [],
   "source": [
    "top_players = iplmatches.player_of_match.value_counts()[:10]\n",
    "#sns.barplot(x=\"day\", y=\"total_bill\", data=tips)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim([0,20])\n",
    "ax.set_ylabel(\"Number of Awards\")\n",
    "ax.set_xlabel(\"Name of Players\")\n",
    "ax.set_title(\"Top player of the match Winners\")\n",
    "#top_players.plot.bar()\n",
    "sns.barplot(x = top_players.index, y = top_players, orient='v', palette=\"RdBu\");\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ba135588365f94249adbf045dac497194e38399"
   },
   "outputs": [],
   "source": [
    "## Question regarding top bastsmen and top bowlers in history of IPL.\n",
    "\n",
    "batsman_runsperseason = batsmen.groupby(['season', 'batting_team', 'batsman'])['batsman_runs'].sum().reset_index()\n",
    "batsman_runsperseason = batsman_runsperseason.groupby(['season', 'batsman'])['batsman_runs'].sum().unstack().T\n",
    "batsman_runsperseason['Total'] = batsman_runsperseason.sum(axis=1) #add total column to find batsman with the highest runs\n",
    "batsman_runsperseason = batsman_runsperseason.sort_values(by = 'Total', ascending = False).drop('Total', 1)\n",
    "ax.set_ylabel('Number of Runs')\n",
    "ax = batsman_runsperseason[:8].T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47e5b249775ec9bddc22fc9d2e3fff8fe54520d1"
   },
   "outputs": [],
   "source": [
    "bowler_wicketsperseason = bowlers.groupby(['season', 'bowling_team', 'bowler'])['wickets'].sum().reset_index()\n",
    "bowler_wicketsperseason = bowler_wicketsperseason.groupby(['season', 'bowler'])['wickets'].sum().unstack().T\n",
    "bowler_wicketsperseason ['Total'] = bowler_wicketsperseason .sum(axis=1) #add total column to find bowler with the highest number of wickets\n",
    "bowler_wicketsperseason  = bowler_wicketsperseason .sort_values(by = 'Total', ascending = False).drop('Total', 1)\n",
    "plt.ylabel('Number of Wickets')\n",
    "ax = bowler_wicketsperseason [:8].T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d440067211b542ae0eeccb252ad70fe5e252c7e0"
   },
   "outputs": [],
   "source": [
    "runs_scored=batsmen.groupby(['batsman'])['batsman_runs'].sum()\n",
    "runs_scored=runs_scored.sort_values(ascending=False)\n",
    "top10runs = runs_scored.head(8)\n",
    "top10runs.plot('barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c696bad0dd04bb15d822832a4c35d1543abc2cbc"
   },
   "outputs": [],
   "source": [
    "## Barplot of Runs\n",
    "\n",
    "#sns.barplot(x=\"day\", y=\"total_bill\", data=tips)\n",
    "fig, ax = plt.subplots()\n",
    "#fig.figsize = [16,10]\n",
    "#ax.set_ylim([0,20])\n",
    "ax.set_xlabel(\"Runs\")\n",
    "ax.set_title(\"Winning by Runs - Team Performance\")\n",
    "#top_players.plot.bar()\n",
    "sns.boxplot(y = 'winner', x = 'win_by_runs', data=iplmatches[iplmatches['win_by_runs']>0], orient = 'h'); #palette=\"Blues\");\n",
    "plt.show()\n",
    "\n",
    "## Barplot of Wickets Win\n",
    "\n",
    "#sns.barplot(x=\"day\", y=\"total_bill\", data=tips)\n",
    "fig, ax = plt.subplots()\n",
    "#fig.figsize = [16,10]\n",
    "#ax.set_ylim([0,20])\n",
    "ax.set_title(\"Winning by Wickets - Team Performance\")\n",
    "#top_players.plot.bar()\n",
    "sns.boxplot(y = 'winner', x = 'win_by_wickets', data=iplmatches[iplmatches['win_by_wickets']>0], orient = 'h'); #palette=\"Blues\");\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd0cf81ce781a8d9ab43c999b2fdd00be8c60649"
   },
   "source": [
    "====================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b2bdbcbe5777de74e6806b5de40cdd93f0b5bb8"
   },
   "source": [
    "Now we are going to do some Classification.\n",
    "Please note that I will do very little explaining and more so for the user to explore and figure out the statistical methods used under it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31c47bbd9a8282d6e56982906291fa026883e1ff"
   },
   "outputs": [],
   "source": [
    "# Import the new Dataset.\n",
    "# Now for this dataset, I removed some features that I felt were unnecessary from the original IPL\n",
    "# Dataset. However, you can use that or use the one below with a screenshot of the headings.\n",
    "matches = pandas.read_csv('../input/matches1234.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae075836201b80e65b7e9b8e74ec695c8415311d"
   },
   "outputs": [],
   "source": [
    "matches.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "852b66e8b336cfcd4cc34751d259f92157c90a45"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the dataset that you imported or used before\n",
    "copy_data = matches.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80857b88f5494babbc89f6780367d4e2399f3c0f"
   },
   "outputs": [],
   "source": [
    "# As to ensure data integrity, make sure there are no missing values. In some cases you can take the mean to ensure fairness. In this case\n",
    "# the values missing are types and so I filled them with these names. You could do otherwise if you wish\n",
    "copy_data['city'].fillna('Dubai',inplace=True)\n",
    "copy_data['umpire1'].fillna('Aleem Dar',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9c441fb868968dec8f24f2bb50557c892f3b5d6"
   },
   "outputs": [],
   "source": [
    "# Firstly, we should have a look whether the data is completed or not.\n",
    "# Because the missing value will have an adverse impact on the building of regression model.\n",
    "\n",
    "null_values_col = copy_data.isnull().sum()\n",
    "null_values_col = null_values_col[null_values_col != 0].sort_values(ascending = False).reset_index()\n",
    "null_values_col.columns = [\"variable\", \"number of missing\"]\n",
    "null_values_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b76267cfd83be308627ad55997dc54f37f235d02"
   },
   "outputs": [],
   "source": [
    "print(copy_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d98b5ad2b7689ed62be4431cf93054f5f59fc16"
   },
   "outputs": [],
   "source": [
    "#Create now a dataframe copy of the data and all its rows and named columns.\n",
    "df = DataFrame(copy_data,columns=['team1', 'team2', 'toss_decision','toss_winner','city', 'venue', 'season', 'win_by_runs', 'win_by_wickets', 'umpire1', 'winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3cfa28147347e8ee2c8c12eb3983955765ab050"
   },
   "outputs": [],
   "source": [
    "# Now what we have done is replace the name values with numbers. Regression can only be run with \n",
    "# numbers and not anything else. \n",
    "df['winner'].fillna('Draw', inplace=True)\n",
    "df.replace(['Mumbai Indians','Kolkata Knight Riders','Royal Challengers Bangalore','Deccan Chargers','Chennai Super Kings',\n",
    "                 'Rajasthan Royals','Delhi Daredevils','Gujarat Lions','Kings XI Punjab',\n",
    "                 'Sunrisers Hyderabad','Rising Pune Supergiants','Kochi Tuskers Kerala','Pune Warriors']\n",
    "                ,['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW'],inplace=True)\n",
    "\n",
    "encode = {'team1': {'MI':1,'KKR':2,'RCB':3,'DC':4,'CSK':5,'RR':6,'DD':7,'GL':8,'KXIP':9,'SRH':10,'RPS':11,'KTK':12,'PW':13},\n",
    "          'team2': {'MI':1,'KKR':2,'RCB':3,'DC':4,'CSK':5,'RR':6,'DD':7,'GL':8,'KXIP':9,'SRH':10,'RPS':11,'KTK':12,'PW':13},\n",
    "          'toss_winner': {'MI':1,'KKR':2,'RCB':3,'DC':4,'CSK':5,'RR':6,'DD':7,'GL':8,'KXIP':9,'SRH':10,'RPS':11,'KTK':12,'PW':13},\n",
    "          'winner': {'MI':1,'KKR':2,'RCB':3,'DC':4,'CSK':5,'RR':6,'DD':7,'GL':8,'KXIP':9,'SRH':10,'RPS':11,'KTK':12,'PW':13,'Draw':14}}\n",
    "df.replace(encode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "742f5d348933b28c17540959aa3fe9248b113664"
   },
   "outputs": [],
   "source": [
    "dicVal = encode['winner']\n",
    "print(dicVal['MI']) #key value\n",
    "print(list(dicVal.keys())[list(dicVal.values()).index(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94dded967bdc07048b5eb56b0862314a02d0691d"
   },
   "outputs": [],
   "source": [
    "# If any of the types are objects, then this needs to be changed to integers\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c78a5c603c8e1c01c201e537e1f12de4efe25cc"
   },
   "outputs": [],
   "source": [
    "# This allows any columns to be changed with the corresponding values.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['toss_decision', 'city', 'venue', 'umpire1']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4df20e32740b430c4a3cb3c2fcc6285c73222bc0"
   },
   "outputs": [],
   "source": [
    "#Compare the data at the beginning to now, ensuring no string value remains.\n",
    "df.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "264cbfe4fc8f47d9a3a6b2eee00ee0cbe0f604dd"
   },
   "outputs": [],
   "source": [
    "# Now we are going to split the training and test models in a typical 60:20:20 set.\n",
    "x = df[['team1', 'team2', 'toss_decision','toss_winner','city', 'venue', 'season', 'win_by_runs', 'win_by_wickets', 'umpire1']]\n",
    "y = df[['winner']]\n",
    "\n",
    "x_model, x_test, y_model, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_model, y_model, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffb9b50172124c2b35f2161d5fcbf9983639ed26"
   },
   "outputs": [],
   "source": [
    "# Model Tuning\n",
    "\n",
    "# 5-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "def rmse_cv(model):\n",
    "    kf = KFold(5, shuffle=True, random_state= 42).get_n_splits(x_model.values)\n",
    "    predictions = model.predict(x_test)\n",
    "    rmse= np.sqrt(-cross_val_score(model, x_model.values, y_model, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "x_model, x_test, y_model, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_model, y_model, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73145a0a14011e6f3514241974c2f4ceaaf565a2"
   },
   "outputs": [],
   "source": [
    "# How to find K?\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_scores = []\n",
    "validation_scores = []\n",
    "\n",
    "x_model_values = x_model.values\n",
    "y_model_values = y_model.values\n",
    "\n",
    "# 5-fold cross validation\n",
    "\n",
    "kfold = KFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "for i in range(1,20):\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    \n",
    "    tr_scores = []\n",
    "    va_scores = []\n",
    "    \n",
    "    for a, b in kfold.split(x_model_values):\n",
    "\n",
    "        x_train_fold, y_train_fold = x_model_values[a], y_model_values[a]\n",
    "        x_val_fold, y_val_fold = x_model_values[b], y_model_values[b]\n",
    "        \n",
    "        knn.fit(x_train_fold, y_train_fold.ravel())\n",
    "        \n",
    "        va_scores.append(knn.score(x_val_fold, y_val_fold))\n",
    "        tr_scores.append(knn.score(x_train_fold, y_train_fold))\n",
    "        \n",
    "    validation_scores.append(np.mean(va_scores))\n",
    "    train_scores.append(np.mean(tr_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96b54c12b55c34d9cdc7010c36afd500aad21e42"
   },
   "outputs": [],
   "source": [
    "plt.title('k-NN Varying number of neighbours')\n",
    "plt.plot(range(1,20),validation_scores,label=\"Validation\")\n",
    "plt.plot(range(1,20),train_scores,label=\"Train\")\n",
    "plt.legend()\n",
    "plt.xticks(range(1,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9de6a734d639dffb1f12bb713f7e7456ff947e0b"
   },
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "\n",
    "# How KNN algorithm performs in both small-size data and big-size data \n",
    "\n",
    "# choose an acceptable color\n",
    "# https://www.spycolor.com/ff8040\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(KNeighborsClassifier(5), \n",
    "        x_model, \n",
    "        y_model,\n",
    "        # Number of folds in cross-validation\n",
    "        cv=5,\n",
    "        # Evaluation metric\n",
    "        scoring='accuracy',\n",
    "        # Use all computer cores\n",
    "        n_jobs=-1, \n",
    "        # 50 different sizes of the training set\n",
    "        train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#ff8040\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, val_mean, color=\"#40bfff\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve \\n k-fold=5, number of neighbours=5\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd35c04e48adc4be7689317ad20f1d782211dc1f"
   },
   "outputs": [],
   "source": [
    "# curse of dimensionality\n",
    "\n",
    "# one or two features are simple, but it cannot recognize and divide our categories. more features means\n",
    "# more evidence in different dimensions, but it could cause overfitting.\n",
    "\n",
    "x = df[['team1', 'team2', 'toss_decision','toss_winner','city', 'venue', 'season', 'win_by_runs', 'win_by_wickets', 'umpire1']]\n",
    "y = df[['winner']]\n",
    "\n",
    "x_model, x_test, y_model, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_model, y_model, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "103ae3cb5db210be290dcc86caf3e53d00055f19"
   },
   "outputs": [],
   "source": [
    "# [:, :2]extract columns\n",
    "\n",
    "# convert[[1],[2],[3],...] to [1,2,3,4,0]\n",
    "# x_train_values_list = np.array(x_train_values).tolist() \n",
    "\n",
    "'''\n",
    "y_train_value = [j for i in y_train_values for j in i] - delete sublists to just one list\n",
    "\n",
    "dimensionality = []\n",
    "for i in range(10):\n",
    "\n",
    "a = [item[:, :2] for item in list(x_train_values)]\n",
    "print(a)\n",
    "'''\n",
    "\n",
    "d_train = []\n",
    "d_val = []\n",
    "\n",
    "x_train_values = x_train.values\n",
    "y_train_values = y_train.values\n",
    "x_val_values = x_val.values\n",
    "y_val_values = y_val.values\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    x_train_value = x_train_values[:,:i].tolist() #convert dataframe\n",
    "    x_val_value = x_val_values[:,:i].tolist()\n",
    "    \n",
    "    knn = KNeighborsClassifier(5)\n",
    "    Knn = knn.fit(x_train_value, y_train_values.ravel())\n",
    "\n",
    "    d_train.append(Knn.score(x_train_value, y_train_values))\n",
    "    d_val.append(Knn.score(x_val_value, y_val_values))\n",
    "\n",
    "plt.title('K-NN Curse of Dimensionality')\n",
    "plt.plot(range(1,11),d_val,label=\"Validation\")\n",
    "plt.plot(range(1,11),d_train,label=\"Train\")\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Score (Accuracy)')\n",
    "plt.legend()\n",
    "plt.xticks(range(1,11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "014f71777327fdc64f28617ff2f45fa4702eb45a"
   },
   "outputs": [],
   "source": [
    "# The best result is captured at k = 5 hence it is used for the final model.\n",
    "\n",
    "#Setup a knn classifier with k neighbors\n",
    "\n",
    "kfold = KFold(5, shuffle=True, random_state=42)\n",
    "knn = KNeighborsClassifier(5)\n",
    "\n",
    "for m,n in kfold.split(x_model_values):\n",
    "        \n",
    "        x_train_fold, y_train_fold = x_model_values[m], y_model_values[m]\n",
    "        \n",
    "        Knn = knn.fit(x_train_fold, y_train_fold.ravel())\n",
    "\n",
    "print('When k=5, the testing score(accuracy) is: ')\n",
    "print(Knn.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1e3f9da08264dbfb3db9015a42df918a63ff649"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "y_predict_knn = knn.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_predict_knn) \n",
    "\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW'], \n",
    "                     columns = ['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW' ])\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('KNN \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_predict_knn)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44901a7f90151cda3ce67e47e9a3cb997b9b7406"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39a297bd676b1164b11c2623d2139bfbb93f20ff"
   },
   "outputs": [],
   "source": [
    "##Using SVM - Note that I have not fine tuned this method. This is just for practice purposes and ensuring I can correctly do the data science behind it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55c299577dbeeab1269f8c7af7c046358608bb39"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "classifier = SVC(gamma = 'auto')\n",
    "svm_model = OneVsRestClassifier(classifier, n_jobs=1).fit(x_train, y_train)\n",
    "\n",
    "print(svm_model.score(x_train,y_train))\n",
    "print(svm_model.score(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "076b26cb0b69af625166011db01c313145cdbd5a"
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy=[]\n",
    "gamma=[0.0001, 0.001, 0.005, 0.01, 0.1, 0.2, 0.3, 0.5, 0.1]\n",
    "\n",
    "for a in gamma:\n",
    "    classifier = SVC(C=1, \n",
    "        kernel='rbf', \n",
    "        degree=2, \n",
    "        gamma=a, \n",
    "        coef0=1,\n",
    "        shrinking=True, \n",
    "        tol=0.5,\n",
    "        probability=False, \n",
    "        cache_size=200, \n",
    "        class_weight=None,\n",
    "        verbose=False, \n",
    "        max_iter=-1, \n",
    "        decision_function_shape=None, \n",
    "        random_state=None)\n",
    "    svm_model = OneVsRestClassifier(classifier, n_jobs=1)\n",
    "    svm_model.fit(x_train, y_train)\n",
    "    predict=svm_model.predict(x_val)\n",
    "    accuracy.append(svm_model.score(x_val,y_val))\n",
    "print(accuracy)\n",
    "plt.scatter(gamma, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dce92000bff489221bcac40b89fb807a0ff098f9"
   },
   "outputs": [],
   "source": [
    "gamma=np.arange(0.0001, 0.005, 0.0003) \n",
    "accuracy=[]\n",
    "\n",
    "for a in gamma:\n",
    "    classifier = SVC(C=1, \n",
    "        kernel='rbf', \n",
    "        degree=2, \n",
    "        gamma=a, \n",
    "        coef0=1,\n",
    "        shrinking=True, \n",
    "        tol=0.5,\n",
    "        probability=False, \n",
    "        cache_size=200, \n",
    "        class_weight=None,\n",
    "        verbose=False, \n",
    "        max_iter=-1, \n",
    "        decision_function_shape=None, \n",
    "        random_state=None)\n",
    "    svm_model = OneVsRestClassifier(classifier, n_jobs=1)\n",
    "    svm_model.fit(x_train, y_train)\n",
    "    predict=svm_model.predict(x_val)\n",
    "    accuracy.append(svm_model.score(x_val,y_val))\n",
    "print(accuracy)\n",
    "plt.scatter(gamma, accuracy)\n",
    "plt.scatter(gamma, accuracy)\n",
    "plt.title(\"Finding Gamma\")\n",
    "plt.xlabel(\"Gamma\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36d538597fdfbcfafee099a33ed85fe2dfe7b3dc"
   },
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "C=np.arange(1,10,1) \n",
    "\n",
    "for a in C:\n",
    "    classifier = SVC(C=a, \n",
    "        kernel='rbf', \n",
    "        degree=2, \n",
    "        gamma=0.0013, \n",
    "        coef0=1,\n",
    "        shrinking=True, \n",
    "        tol=0.5,\n",
    "        probability=False, \n",
    "        cache_size=200, \n",
    "        class_weight=None,\n",
    "        verbose=False, \n",
    "        max_iter=-1, \n",
    "        decision_function_shape=None, \n",
    "        random_state=None)\n",
    "    svm_model = OneVsRestClassifier(classifier, n_jobs=1)\n",
    "    svm_model.fit(x_train, y_train)\n",
    "    predict=svm_model.predict(x_val)\n",
    "    accuracy.append(svm_model.score(x_val,y_val))\n",
    "print(accuracy)\n",
    "plt.scatter(C, accuracy)\n",
    "plt.title(\"Finding C\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a8583a8f7e8baa87390d94211c1ad3188075659"
   },
   "outputs": [],
   "source": [
    "classifier = SVC(C=9, # Regularization parameter\n",
    "        kernel='rbf', # kernel type, rbf working fine here\n",
    "        degree=2, # default value\n",
    "        gamma=0.005, # kernel coefficient\n",
    "        coef0=1, # change to 1 from default value of 0.0\n",
    "        shrinking=True, # using shrinking heuristics\n",
    "        tol=0.5, # stopping criterion tolerance \n",
    "        probability=False, # no need to enable probability estimates\n",
    "        cache_size=200, # 200 MB cache size\n",
    "        class_weight=None, # all classes are treated equally \n",
    "        verbose=False, # print the logs \n",
    "        max_iter=-1, # no limit, let it run\n",
    "        decision_function_shape=None, # will use one vs rest explicitly \n",
    "        random_state=None)\n",
    "svm_model = OneVsRestClassifier(classifier, n_jobs=1).fit(x_train, y_train)\n",
    "\n",
    "print(svm_model.score(x_train,y_train))\n",
    "print(svm_model.score(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30a8293fdc9809ade8ee7b2348dcc0a039203cb9"
   },
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(OneVsRestClassifier(classifier, n_jobs=1), \n",
    "        x_model, \n",
    "        y_model,\n",
    "        # Number of folds in cross-validation\n",
    "        cv=5,\n",
    "        # Evaluation metric\n",
    "        scoring='accuracy',\n",
    "        # Use all computer cores\n",
    "        # 50 different sizes of the training set\n",
    "        train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#ff8040\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, val_mean, color=\"#40bfff\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve \\n C=1, gamma=0.0013\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5969910eb83dfb729483d3a473b6a20345b745c"
   },
   "outputs": [],
   "source": [
    "# curse of dimensionality\n",
    "\n",
    "# one or two features are simple, but it cannot recognize and divide our categories. more features means\n",
    "# more evidence in different dimensions, but it could cause overfitting.\n",
    "\n",
    "# https://thispointer.com/select-rows-columns-by-name-or-index-in-dataframe-using-loc-iloc-python-pandas/\n",
    "\n",
    "d_train = []\n",
    "d_val = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    x_train_index = x_train.iloc[: , 0:i]\n",
    "    x_val_index = x_val.iloc[: , 0:i]\n",
    "    \n",
    "    classifier = SVC(C=9, # Regularization parameter\n",
    "                    kernel='rbf', # kernel type, rbf working fine here\n",
    "                    degree=2, # default value\n",
    "                    gamma=0.005, # kernel coefficient\n",
    "                    coef0=1, # change to 1 from default value of 0.0\n",
    "                    shrinking=True, # using shrinking heuristics\n",
    "                    tol=0.5, # stopping criterion tolerance \n",
    "                    probability=False, # no need to enable probability estimates\n",
    "                    cache_size=200, # 200 MB cache size\n",
    "                    class_weight=None, # all classes are treated equally \n",
    "                    verbose=False, # print the logs \n",
    "                    max_iter=-1, # no limit, let it run\n",
    "                    decision_function_shape=None, # will use one vs rest explicitly \n",
    "                    random_state=None)\n",
    "    svm_model = OneVsRestClassifier(classifier, n_jobs=1).fit(x_train_index, y_train)\n",
    "\n",
    "    d_train.append(svm_model.score(x_train_index, y_train))\n",
    "    d_val.append(svm_model.score(x_val_index, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08e2165387bb4c5ae826f1bc1ea33acc3a901889"
   },
   "outputs": [],
   "source": [
    "plt.title('SVM Curse of Dimensionality')\n",
    "plt.plot(range(1,11),d_val,label=\"Validation\")\n",
    "plt.plot(range(1,11),d_train,label=\"Train\")\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Score (Accuracy)')\n",
    "plt.legend()\n",
    "plt.xticks(range(1,11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75cbcdd031c33d4cd6c11b49eaabc639506abc42"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "664e97f28af0e01b724e6cc7df95e3c650bdfbed"
   },
   "outputs": [],
   "source": [
    "## Using Naive Bayes Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2552642f3964a647d9a8087678b294b58e207305"
   },
   "outputs": [],
   "source": [
    "# NB assumes that the features themselves are not correlated to each other. Therefore, if the collinearity of our features are low, the model will perform better.\n",
    "\n",
    "x = df[['team1', 'team2', 'toss_decision','toss_winner','city', 'venue', 'season', 'win_by_runs', 'win_by_wickets', 'umpire1']]\n",
    "y = df[['winner']]\n",
    "\n",
    "x_model, x_test, y_model, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_model, y_model, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb2632f2a2395841ac3a576f02e0e1bfc9de32a8"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "nb_model = gaussian.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print(nb_model.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a3e24efe4db6a14ae685782b769dfcb6b071b3e"
   },
   "outputs": [],
   "source": [
    "train_score = []\n",
    "val_score = []\n",
    "a = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 1]\n",
    "\n",
    "#for i in np.arange(1,20):\n",
    "for i in a:\n",
    "    gaussian = GaussianNB(priors=None, var_smoothing=i)\n",
    "    nb_model = gaussian.fit(x_train, y_train.values.ravel())\n",
    "    train_score.append(nb_model.score(x_train, y_train))\n",
    "    val_score.append(nb_model.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a702b2db9e61934f5637252000f74221ec69598"
   },
   "outputs": [],
   "source": [
    "plt.plot(a,train_score)\n",
    "plt.plot(a,val_score)\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.title('Naive Bayes Tuning')\n",
    "plt.xlabel('Variance Smoothing')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52c9156182df3f64b7462370ea1d546030eefa17"
   },
   "outputs": [],
   "source": [
    "gaussian = GaussianNB(priors=None, var_smoothing=0.03)\n",
    "nb_model = gaussian.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print(nb_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4885c3ef1a372ae68eb4dc9caa80c65fcea57e4a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "y_predict_nb = nb_model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_predict_nb) \n",
    "\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW'], \n",
    "                     columns = ['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW' ])\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Naive Bayes \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_predict_nb)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11ae47cccca19ba89fc2d05ef72e8a33773b4686"
   },
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(OneVsRestClassifier(GaussianNB(priors=None, var_smoothing=0.1)), \n",
    "        x_model, \n",
    "        y_model,\n",
    "        # Number of folds in cross-validation\n",
    "        cv=5,\n",
    "        # Evaluation metric\n",
    "        scoring='accuracy',\n",
    "        # Use all computer cores\n",
    "        # 50 different sizes of the training set\n",
    "        train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#ff8040\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, val_mean, color=\"#40bfff\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"NB Learning Curve \\n \")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c23a10c80ab0bb11808b9ff0d74ba52a497fae5e"
   },
   "outputs": [],
   "source": [
    "d_train = []\n",
    "d_val = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    x_train_index = x_train.iloc[: , 0:i]\n",
    "    x_val_index = x_val.iloc[: , 0:i]\n",
    "    \n",
    "    classifier = GaussianNB(priors=None, var_smoothing=0.1)\n",
    "    nb_model = gaussian.fit(x_train_index, y_train.values.ravel())\n",
    "\n",
    "    d_train.append(nb_model.score(x_train_index, y_train))\n",
    "    d_val.append(nb_model.score(x_val_index, y_val))\n",
    "plt.title('Naive Bayes Curse of Dimensionality')\n",
    "plt.plot(range(1,11),d_val,label=\"Validation\")\n",
    "plt.plot(range(1,11),d_train,label=\"Train\")\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Score (Accuracy)')\n",
    "plt.legend()\n",
    "plt.xticks(range(1,11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fad1502a88db6963d11218ac1e317029ca23272"
   },
   "outputs": [],
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca52d2d0e1ffb08ffb7b47fbf231d7890173154f"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(x_train, y_train)\n",
    "print(decision_tree_model.score(x_train,y_train))\n",
    "print(decision_tree_model.score(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e34b6a79e4b5886eff18ac705bd4cef22527b33"
   },
   "outputs": [],
   "source": [
    "plt.bar(range(len(x_train.columns.values)), decision_tree_model.feature_importances_)\n",
    "plt.xticks(range(len(x_train.columns.values)),x_train.columns.values, rotation= 45)\n",
    "plt.title('Figure 1.7 Importance of each Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82ac5d310034da26b0189b41ee55389339350492"
   },
   "outputs": [],
   "source": [
    "train_score = []\n",
    "val_score = []\n",
    "for depth in np.arange(1,11):\n",
    "    decision_tree = tree.DecisionTreeClassifier(max_depth = depth,min_samples_leaf = 5)\n",
    "    decision_tree.fit(x_train, y_train)\n",
    "    train_score.append(decision_tree.score(x_train, y_train))\n",
    "    val_score.append(decision_tree.score(x_val, y_val))\n",
    "\n",
    "plt.plot(np.arange(1,11),train_score)\n",
    "plt.plot(np.arange(1,11),val_score)\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.title('Decision Tree Tuning')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e8a8fbd85e2a5c43d4910584447e131d40e33f7"
   },
   "outputs": [],
   "source": [
    "train_score = []\n",
    "val_score = []\n",
    "for depth in np.arange(1,15):\n",
    "    decision_tree = tree.DecisionTreeClassifier(max_depth = depth,min_samples_leaf = 5)\n",
    "    decision_tree.fit(x_train, y_train)\n",
    "    train_score.append(decision_tree.score(x_train, y_train))\n",
    "    val_score.append(decision_tree.score(x_val, y_val))\n",
    "\n",
    "plt.plot(np.arange(1,15),train_score)\n",
    "plt.plot(np.arange(1,15),val_score)\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.title('Decision Tree Tuning')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a64fae5b509e964579e9b188bc9f7d4d0371d25"
   },
   "outputs": [],
   "source": [
    "train_score = []\n",
    "val_score = []\n",
    "for leaf in np.arange(1,20):\n",
    "    decision_tree = tree.DecisionTreeClassifier(max_depth = 9, min_samples_leaf = leaf)\n",
    "    decision_tree.fit(x_train, y_train)\n",
    "    train_score.append(decision_tree.score(x_train, y_train))\n",
    "    val_score.append(decision_tree.score(x_val, y_val))\n",
    "\n",
    "plt.plot(np.arange(1,20),train_score)\n",
    "plt.plot(np.arange(1,20),val_score)\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.title('Decision Tree Tuning')\n",
    "plt.xlabel('Minimum Samples Leaf')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1914b0b4b418c495cde4d1111ea4e47c4cbb238c"
   },
   "outputs": [],
   "source": [
    "my_decision_tree_model = DecisionTreeClassifier(max_depth = 9, min_samples_leaf = 3)\n",
    "my_decision_tree_model.fit(x_train, y_train)\n",
    "print(my_decision_tree_model.score(x_train,y_train))\n",
    "print(my_decision_tree_model.score(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04f89146d46fe33da31e33c6ae2d21c4009313b4"
   },
   "outputs": [],
   "source": [
    "print(my_decision_tree_model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c73ab47a04f7963c63aa76ee736dfb3c6fcd8166"
   },
   "outputs": [],
   "source": [
    "y_predict_decision = my_decision_tree_model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_predict_decision) \n",
    "\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW'], \n",
    "                     columns = ['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW' ])\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Decision Tree \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_predict_decision)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b86df516cd7f1a055a9b80c92c738ec6eea3fd0"
   },
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "train_sizes, train_scores, val_scores = learning_curve(OneVsRestClassifier(DecisionTreeClassifier(max_depth = 5, min_samples_leaf = 6)), \n",
    "        x_model, \n",
    "        y_model,\n",
    "        # Number of folds in cross-validation\n",
    "        cv=5,\n",
    "        # Evaluation metric\n",
    "        scoring='accuracy',\n",
    "        # Use all computer cores\n",
    "        # 50 different sizes of the training set\n",
    "        train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#ff8040\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, val_mean, color=\"#40bfff\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Decision Tree Learning Curve \\n \")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63e72b0335384c3ce3012aaf1feb6ea63867c6a7"
   },
   "outputs": [],
   "source": [
    "# Curse of Dimensionality\n",
    "\n",
    "d_train = []\n",
    "d_val = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    x_train_index = x_train.iloc[: , 0:i]\n",
    "    x_val_index = x_val.iloc[: , 0:i]\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(max_depth = 5, min_samples_leaf = 6)\n",
    "    dt_model = classifier.fit(x_train_index, y_train.values.ravel())\n",
    "\n",
    "    d_train.append(dt_model.score(x_train_index, y_train))\n",
    "    d_val.append(dt_model.score(x_val_index, y_val))\n",
    "plt.title('Decision Tree Curse of Dimensionality')\n",
    "plt.plot(range(1,11),d_val,label=\"Validation\")\n",
    "plt.plot(range(1,11),d_train,label=\"Train\")\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Score (Accuracy)')\n",
    "plt.legend()\n",
    "plt.xticks(range(1,11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f066cc0611d0af975365105f629fb0d2831e2aa"
   },
   "outputs": [],
   "source": [
    "## Using Logisitic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ffdc990a377a55b8e6989f425c25f0670f17207"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0dc9333fb4b2bf58a08d8684db49832b382e37d"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print(logistic_model.score(x_train,y_train))\n",
    "print(logistic_model.score(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "017755aaeed27c13ad85887e26e7689af39a1f63"
   },
   "outputs": [],
   "source": [
    "train_score = []\n",
    "val_score=[]\n",
    "\n",
    "for i in np.arange(1,80):\n",
    "    \n",
    "    logistic_model = LogisticRegression(penalty = 'l2', C = i,random_state = 0)\n",
    "    \n",
    "    logistic_model.fit(x_train,y_train.values.ravel()) \n",
    "    \n",
    "    train_score.append(logistic_model.score(x_train, y_train))\n",
    "    val_score.append(logistic_model.score(x_val,y_val))\n",
    "\n",
    "    \n",
    "plt.plot(np.arange(1,80),train_score)\n",
    "plt.plot(np.arange(1,80),val_score)\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.title('Logistic Regression Tuning')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90960ed8a2386eeb426939d30b12e5ab0507f7a0"
   },
   "outputs": [],
   "source": [
    "my_logistic_regression_model = LogisticRegression(penalty = 'l2', C = 48, random_state = 0)\n",
    "my_logistic_regression_model.fit(x_train, y_train)\n",
    "print(my_logistic_regression_model.score(x_train,y_train))\n",
    "print(my_logistic_regression_model.score(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddffbbf1b25a8bc71b4cd0528a65decdbb6de0e1"
   },
   "outputs": [],
   "source": [
    "print(my_logistic_regression_model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcff2b15e16ab0c9d58e10371e92fb57bcd44e01"
   },
   "outputs": [],
   "source": [
    "y_predict_logit = my_logistic_regression_model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_predict_logit) \n",
    "\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW'], \n",
    "                     columns = ['MI','KKR','RCB','DC','CSK','RR','DD','GL','KXIP','SRH','RPS','KTK','PW' ])\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Logistic Regression \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_predict_logit)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98b6edfd7d91cd3bc7cf56882f2ba3f15bb88322"
   },
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(OneVsRestClassifier(LogisticRegression(penalty = 'l2', C = 48, random_state = 0)), \n",
    "        x_model, \n",
    "        y_model,\n",
    "        # Number of folds in cross-validation\n",
    "        cv=5,\n",
    "        # Evaluation metric\n",
    "        scoring='accuracy',\n",
    "        # Use all computer cores\n",
    "        # 50 different sizes of the training set\n",
    "        train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#ff8040\",  label=\"Training score\")\n",
    "plt.plot(train_sizes, val_mean, color=\"#40bfff\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Logistic Regression Learning Curve \\n \")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f68327bd96b81f694bbd00071e5eac6392ba00a4"
   },
   "outputs": [],
   "source": [
    "# Curse of Dimensionality\n",
    "\n",
    "d_train = []\n",
    "d_val = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    x_train_index = x_train.iloc[: , 0:i]\n",
    "    x_val_index = x_val.iloc[: , 0:i]\n",
    "    \n",
    "    classifier = LogisticRegression(penalty = 'l2', C = 48, random_state = 0)\n",
    "    lr_model = classifier.fit(x_train_index, y_train.values.ravel())\n",
    "\n",
    "    d_train.append(lr_model.score(x_train_index, y_train))\n",
    "    d_val.append(lr_model.score(x_val_index, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "697e3661e368d56202b744b202fed5dab03205c8"
   },
   "outputs": [],
   "source": [
    "plt.title('Logistic Regression Curse of Dimensionality')\n",
    "plt.plot(range(1,11),d_val,label=\"Validation\")\n",
    "plt.plot(range(1,11),d_train,label=\"Train\")\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Score (Accuracy)')\n",
    "plt.legend()\n",
    "plt.xticks(range(1,11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32877e336c081ea7337dfaa1dc20cdf4d51cecf4"
   },
   "outputs": [],
   "source": [
    "print(\"Logistic Regression \\nAccuracy:{0:.4f}\".format(accuracy_score(y_test, y_predict_logit)))\n",
    "print(\"Decision Tree \\nAccuracy:{0:.4f}\".format(accuracy_score(y_test, y_predict_decision)))\n",
    "print(\"Naive Bayes \\nAccuracy:{0:.4f}\".format(accuracy_score(y_test, y_predict_nb)))\n",
    "print(\"KNN Accuracy \\nAccuracy:{0:.4f}\".format(accuracy_score(y_test, y_predict_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d87a8d68f66f5341c7065fa3b2544947a41733b"
   },
   "source": [
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c25d874617abde65671b68c66a8928fc0dad3717"
   },
   "source": [
    "Now we will be running the bowler's Regression to estimate the total number of runs conceded when they bowl in the IPL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "424fac6afdae6e2972426bfd3831bf8c29e19697"
   },
   "source": [
    "At this point, it is important to remember that we earlier grouped the deliveries data set that is viable for each and every bowler. Having named this as a data strucure, we save this file as a csv and now we call upon it seperately. As with the classification, I have omitted certain columns. You can do so otherwise or keep them at your discretion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4506ec9e6867d020541b6c00ebf77ce3d72758b5"
   },
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "Bowlers = pandas.read_csv('../input/Bowlers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa52eeb49a0aeab494f3dad31ca8a082152fde51"
   },
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "copy_data = Bowlers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44ca4c7e6906140e28292060a5d74179ef55d879"
   },
   "outputs": [],
   "source": [
    "#Ensure there are no missing values\n",
    "null_values_col = copy_data.isnull().sum()\n",
    "null_values_col = null_values_col[null_values_col != 0].sort_values(ascending = False).reset_index()\n",
    "null_values_col.columns = [\"variable\", \"number of missing\"]\n",
    "null_values_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02f936d53c8b47712c1b970a40cb49c3a3b2cca8"
   },
   "outputs": [],
   "source": [
    "copy_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d04b2c7c8cad108973eddb0162c305566425d4dd"
   },
   "outputs": [],
   "source": [
    "#This shows us the top correlated variables with respect to one another\n",
    "df = DataFrame(copy_data,columns=['over', 'wide_runs', 'noball_runs', 'runs', 'extras', 'wickets', 'Econ'])\n",
    "\n",
    "'''\n",
    "pandas.DataFrame.corr\n",
    "method : {pearson, kendall, spearman}\n",
    "pearson : standard correlation coefficient\n",
    "kendall : Kendall Tau correlation coefficient\n",
    "spearman : Spearman rank correlation\n",
    "\n",
    "min_periods : int, optional\n",
    "Minimum number of observations required per pair of columns to have a valid result. Currently only available for pearson and spearman correlation\n",
    "'''\n",
    "\n",
    "corrmat = df.corr(method='pearson', min_periods=1)\n",
    "r_square = corrmat ** 2\n",
    "\n",
    "## Top 8 correlated variables\n",
    "k = 9 #number of variables for heatmap\n",
    "cols = r_square.nlargest(k, 'runs')['runs'].index\n",
    "cm = df[cols].corr()\n",
    "cm_square = cm ** 2\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm_square, cbar=False, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "acc16118cd564980cacf599098860c3b54d188c7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# RMSE for testing data\n",
    "\n",
    "def rmse_model(model, x_test, y_test):\n",
    "    predictions = model.predict(x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, y_test))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2bfac8b4cb6b103d81cbfe015a8f48ae17a3365b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df[['over', 'wide_runs', 'noball_runs','extras', 'wickets', 'Econ']]\n",
    "y = df[['runs']]\n",
    "\n",
    "x_model, x_test, y_model, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_model, y_model, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7c17799246ef0500548be69f3cf0085231697fc"
   },
   "outputs": [],
   "source": [
    "print(\"the number of data for training:\")\n",
    "print(y_train.count())\n",
    "print(\"the number of data for validation:\")\n",
    "print(y_val.count())\n",
    "print(\"the number of data for testing:\")\n",
    "print(y_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eeb33c9ad00facc5f60ab22f68cf4c9d5f20c448"
   },
   "outputs": [],
   "source": [
    "#Basic Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(x_train, y_train)\n",
    "\n",
    "print(rmse_model(linear_regression, x_test, y_test))\n",
    "print(linear_regression.coef_)\n",
    "print(linear_regression.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9ea9a20091fff5ea72ebdbec492ed13a7ca66d4"
   },
   "outputs": [],
   "source": [
    "# Bias-Variance Trade-off\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "train_rmses = []\n",
    "val_rmses = []\n",
    "degrees = range(1,9)\n",
    "\n",
    "for i in degrees:\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=i, include_bias=False)\n",
    "    x_train_poly = poly.fit_transform(x_train)\n",
    "\n",
    "    poly_reg = LinearRegression()\n",
    "    poly_reg.fit(x_train_poly, y_train)\n",
    "    \n",
    "    # training RMSE\n",
    "    y_train_pred = poly_reg.predict(x_train_poly)\n",
    "    train_poly_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    \n",
    "    train_rmses.append(train_poly_rmse)\n",
    "    \n",
    "    # validation RMSE\n",
    "    x_val_poly = poly.fit_transform(x_val)\n",
    "    y_val_pred = poly_reg.predict(x_val_poly)\n",
    "    \n",
    "    val_poly_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    val_rmses.append(val_poly_rmse)\n",
    "\n",
    "    print('degree = %s, training RMSE = %.5f, validation RMSE = %.5f' % (i, train_poly_rmse, val_poly_rmse))\n",
    "        \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(degrees, train_rmses,label= 'training set')\n",
    "ax.plot(degrees, val_rmses,label= 'validation set')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Bias/Variance Trade-off')  \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90e69cb4957f1df2361292b8a0ffb801f4511fa2"
   },
   "outputs": [],
   "source": [
    "# RMSE for testing data\n",
    "\n",
    "second_poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "x_train_poly = second_poly.fit_transform(x_train)\n",
    "\n",
    "second_reg = LinearRegression()\n",
    "second_reg.fit(x_train_poly, y_train)\n",
    "\n",
    "x_test_second_poly = second_poly.fit_transform(x_test)\n",
    "y_test_pred = second_reg.predict(x_test_second_poly)\n",
    "\n",
    "print(rmse_model(second_reg, x_test_second_poly, y_test))\n",
    "print(second_reg.coef_)\n",
    "print(second_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a81d66c42cee3f26e6e05dcd2df395efd753555"
   },
   "outputs": [],
   "source": [
    "# RMSE for testing data\n",
    "\n",
    "second_poly = PolynomialFeatures(degree=1, include_bias=False)\n",
    "x_train_poly = second_poly.fit_transform(x_train)\n",
    "\n",
    "second_reg = LinearRegression()\n",
    "second_reg.fit(x_train_poly, y_train)\n",
    "\n",
    "x_test_second_poly = second_poly.fit_transform(x_test)\n",
    "y_test_pred = second_reg.predict(x_test_second_poly)\n",
    "\n",
    "print(rmse_model(second_reg, x_test_second_poly, y_test))\n",
    "print(second_reg.coef_)\n",
    "print(second_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37bf3506c75b28b2a7984b6286e7bca77cb138c2"
   },
   "outputs": [],
   "source": [
    "#We now use Regularization to test co-efficent effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f4a215f0ac3d866e78b9a4043c1f909e42e578f"
   },
   "outputs": [],
   "source": [
    "# At first, we calculate the RMSE before regularization.\n",
    "\n",
    "poly = PolynomialFeatures(degree=6, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(x_train_poly, y_train)\n",
    "\n",
    "x_test_poly = poly.fit_transform(x_test)\n",
    "y_test_pred = poly_reg.predict(x_test_poly)\n",
    "\n",
    "print(rmse_model(poly_reg, x_test_poly, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6f3858feeb5ca1adf1f7a63c222de13ad6f533a"
   },
   "outputs": [],
   "source": [
    "# RMSE for testing data\n",
    "\n",
    "second_poly = PolynomialFeatures(degree=6, include_bias=False)\n",
    "x_train_poly = second_poly.fit_transform(x_train)\n",
    "\n",
    "second_reg = LinearRegression()\n",
    "second_reg.fit(x_train_poly, y_train)\n",
    "\n",
    "x_test_second_poly = second_poly.fit_transform(x_test)\n",
    "y_test_pred = second_reg.predict(x_test_second_poly)\n",
    "\n",
    "print(rmse_model(second_reg, x_test_second_poly, y_test))\n",
    "print(second_reg.coef_)\n",
    "print(second_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09cec520dafc8741ba7b901c990af3f47321dcfc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "628052c91f804c1b4412e6129851a4ae7a75381e"
   },
   "outputs": [],
   "source": [
    "#Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "78d9a08f8057a8158304a7e91a9403b0d8f40c3c"
   },
   "outputs": [],
   "source": [
    "# Ridge\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "rmse=[]\n",
    "alpha=[1, 2, 5, 10, 20, 30, 40, 50, 75, 100]\n",
    "\n",
    "for a in alpha:\n",
    "    ridge = make_pipeline(PolynomialFeatures(6), Ridge(alpha=a))\n",
    "    ridge.fit(x_train, y_train)\n",
    "    predict=ridge.predict(x_val)\n",
    "    rmse.append(np.sqrt(mean_squared_error(predict, y_val)))\n",
    "print(rmse)\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Hyperparameter: alpha')\n",
    "plt.scatter(alpha, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f5b775aff8b2183e05c74a2987cfce999e14433"
   },
   "outputs": [],
   "source": [
    "# Adjust alpha based on previous result\n",
    "\n",
    "alpha=np.arange(1, 20, 2)\n",
    "rmse=[]\n",
    "\n",
    "for a in alpha:\n",
    "    #ridge=Ridge(alpha=a, copy_X=True, fit_intercept=True)\n",
    "    #ridge.fit(x_train, y_train)\n",
    "    ridge = make_pipeline(PolynomialFeatures(4), Ridge(alpha=a))\n",
    "    ridge.fit(x_train, y_train)\n",
    "    predict=ridge.predict(x_val)\n",
    "    rmse.append(np.sqrt(mean_squared_error(predict, y_val)))\n",
    "print(rmse)\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Hyperparameter: alpha')\n",
    "plt.scatter(alpha, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7d557b834e468cd49863986b01f9d5e5cb35a8a"
   },
   "outputs": [],
   "source": [
    "# Adjust alpha based on previous result\n",
    "\n",
    "alpha=np.arange(1, 5, 0.2)\n",
    "rmse=[]\n",
    "\n",
    "for a in alpha:\n",
    "    #ridge=Ridge(alpha=a, copy_X=True, fit_intercept=True)\n",
    "    #ridge.fit(x_train, y_train)\n",
    "    ridge = make_pipeline(PolynomialFeatures(6), Ridge(alpha=a))\n",
    "    ridge.fit(x_train, y_train)\n",
    "    predict=ridge.predict(x_val)\n",
    "    rmse.append(np.sqrt(mean_squared_error(predict, y_val)))\n",
    "print(rmse)\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Hyperparameter: alpha')\n",
    "plt.scatter(alpha, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bebab36467d69cbf510fb6d4c6a046f64126d8fa"
   },
   "outputs": [],
   "source": [
    "# Use alpha=4.2 to predict the test data\n",
    "\n",
    "ridge = make_pipeline(PolynomialFeatures(6), Ridge(alpha=4.2))\n",
    "ridge_model = ridge.fit(x_train, y_train)\n",
    "\n",
    "predictions = ridge_model.predict(x_test)\n",
    "print(\"Ridge RMSE is: \" + str(rmse_model(ridge_model, x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d53a910af3c44270b82c94da440ce73e750ac1d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2dad264c8915e683926f37b93d007bf257b2eee0"
   },
   "outputs": [],
   "source": [
    "# Lasso\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "rmse=[]\n",
    "alpha=[0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "for a in alpha:\n",
    "    lasso=make_pipeline(PolynomialFeatures(6), Lasso(alpha=a))\n",
    "    lasso.fit(x_train, y_train)\n",
    "    predict=lasso.predict(x_val)\n",
    "    rmse.append(np.sqrt(mean_squared_error(predict, y_val)))\n",
    "print(rmse)\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Hyperparameter: alpha')\n",
    "plt.scatter(alpha, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf38a803c194927d8460eefc948a4a0716ee3ff5"
   },
   "outputs": [],
   "source": [
    "lasso = make_pipeline(PolynomialFeatures(6), Lasso(alpha=0.001))\n",
    "lasso_model = lasso.fit(x_train, y_train)\n",
    "predictions = lasso_model.predict(x_test)\n",
    "print(\"RMSE in Testing : \" + str(rmse_model(lasso_model, x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3061406d7cc07f89b0509985ecb38d2be8a81eb"
   },
   "outputs": [],
   "source": [
    "# Comparison\n",
    "\n",
    "print(\"For testing dataset\\n\")\n",
    "\n",
    "print(\"Linear RMSE is: \" + str(rmse_model(linear_regression, x_test, y_test)))\n",
    "print(\"2nd Polynomial RMSE is: \" + str(rmse_model(second_reg, x_test_second_poly, y_test)))\n",
    "\n",
    "print(\"\\nFor 6th order polynomial (RMSE = 5.027401601327215 before regualarization)\")\n",
    "print(\"Ridge RMSE is: \" + str(rmse_model(ridge_model, x_test, y_test)))\n",
    "print(\"Lasso RMSE is: \" + str(rmse_model(lasso_model, x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1df4ed2457664807c7cbdad5172f07ef4d2ba2a9"
   },
   "outputs": [],
   "source": [
    "data = np.array([['','Parameter','RMSE'],\n",
    "                ['1st-order Poly',1,3.6925289],\n",
    "                ['2nd-order Poly',2,0.0035514],\n",
    "                ['6th-order Poly',4,5.02740160],\n",
    "                ['6th-order Lasso','<0.001',0.0455626],\n",
    "                ['6th-order Ridge',4.2,0.1035378]])\n",
    "                \n",
    "regression_comparison = pd.DataFrame(data=data[1:,1:],\n",
    "                                      index=data[1:,0],\n",
    "                                    columns=data[0,1:])\n",
    "regression_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "379fdeb086cdd095f8d6651495dfb4f0b6653e34"
   },
   "outputs": [],
   "source": [
    "my_ridge = Ridge(alpha = 4.2, normalize = True)\n",
    "my_ridge.fit(x_train, y_train) \n",
    "#pd.Series(my_ridge.coef_,index = ['NBA_DraftNumber', 'Age', 'WS', 'BPM'])\n",
    "my_ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61e2a154e8394e22a6511185b37fb83b8d5146d4"
   },
   "outputs": [],
   "source": [
    "my_lasso = Lasso(alpha = 0.001, normalize = True)\n",
    "my_lasso.fit(x_train, y_train) \n",
    "my_lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffef02436575e97379df15ff086174f6096dc92c"
   },
   "outputs": [],
   "source": [
    "data = np.array([['','over', 'wide_runs', 'noball_runs','extras', 'wickets', 'Econ'],\n",
    "                ['Ridge',1.19244951, 0.2525031 , 0.79495296, 0.285872  , 0.0395364 , 0.33603287],\n",
    "                ['Lasso',8.52176098,  0,  0.53551824,  0.22068013, -0.59004948,  2.48183302]])\n",
    "                \n",
    "regularization_comparison = pd.DataFrame(data=data[1:,1:],\n",
    "                                      index=data[1:,0],\n",
    "                                    columns=data[0,1:])\n",
    "regularization_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "43267d272cb571a65f3c07b25eccca755aa45a69"
   },
   "source": [
    "This is the end of the Project. Please message for any reccomendations or thoughts. I aim to update this within a year using new techniques as I learn. \n",
    "=================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21551e49137467c1831f8d5881a6acf62ac556d1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
